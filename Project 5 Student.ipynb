{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Computational Social Science] Project 5: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will use natural language processing techniques to explore a dataset containing tweets from members of the 116th United States Congress that met from January 3, 2019 to January 2, 2021. The dataset has also been cleaned to contain information about each legislator. Concretely, you will do the following:\n",
    "\n",
    "* Preprocess the text of legislators' tweets\n",
    "* Conduct Exploratory Data Analysis of the text\n",
    "* Use sentiment analysis to explore differences between legislators' tweets\n",
    "* Featurize text with manual feature engineering, frequency-based, and vector-based techniques\n",
    "* Predict legislators' political parties and whether they are a Senator or Representative\n",
    "\n",
    "You will explore two questions that relate to two central findings in political science and examine how they relate to the text of legislators' tweets. First, political scientists have argued that U.S. politics is currently highly polarized relative to other periods in American history, but also that the polarization is asymmetric. Historically, there were several conservative Democrats (i.e. \"blue dog Democrats\") and liberal Republicans (i.e. \"Rockefeller Republicans\"), as measured by popular measurement tools like [DW-NOMINATE](https://en.wikipedia.org/wiki/NOMINATE_(scaling_method)#:~:text=DW\\%2DNOMINATE\\%20scores\\%20have\\%20been,in\\%20the\\%20liberal\\%2Dconservative\\%20scale.). However, in the last few years, there are few if any examples of any Democrat in Congress being further to the right than any Republican and vice versa. At the same time, scholars have argued that this polarization is mostly a function of the Republican party moving further right than the Democratic party has moved left. **Does this sort of asymmetric polarization show up in how politicians communicate to their constituents through tweets?**\n",
    "\n",
    "Second, the U.S. Congress is a bicameral legislature, and there has long been debate about partisanship in the Senate versus the House. The House of Representatives is apportioned by population and all members serve two year terms. In the Senate, each state receives two Senators and each Senator serves a term of six years. For a variety of reasons (smaller chamber size, more insulation from the voters, rules and norms like the filibuster, etc.), the Senate has been argued to be the \"cooling saucer\" of Congress in that it is more bipartisan and moderate than the House. **Does the theory that the Senate is more moderate have support in Senators' tweets?**\n",
    "\n",
    "**Note**: See the project handout for more details on caveats and the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "# punctuation, stop words and English language model\n",
    "from string import punctuation\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# countvectorizer, tfidfvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji\n",
    "\n",
    "# ooh do we need to do this? -P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>name_wikipedia</th>\n",
       "      <th>position</th>\n",
       "      <th>joined_congress_date</th>\n",
       "      <th>birthday</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>district_number</th>\n",
       "      <th>party</th>\n",
       "      <th>trump_2016_state_share</th>\n",
       "      <th>clinton_2016_state_share</th>\n",
       "      <th>obama_2012_state_share</th>\n",
       "      <th>romney_2012_state_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.081010e+18</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>2019-01-03T21:23:00-05:00</td>\n",
       "      <td>Great news for Baldwin County! The economy of ...</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>Rep</td>\n",
       "      <td>8-Jan-14</td>\n",
       "      <td>2/16/1955</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1,318,255</td>\n",
       "      <td>729,547</td>\n",
       "      <td>795,696</td>\n",
       "      <td>1,255,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.080880e+18</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>2019-01-03T12:30:38-05:00</td>\n",
       "      <td>Outstanding news today from @Airbus! @JetBlue ...</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>Rep</td>\n",
       "      <td>8-Jan-14</td>\n",
       "      <td>2/16/1955</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1,318,255</td>\n",
       "      <td>729,547</td>\n",
       "      <td>795,696</td>\n",
       "      <td>1,255,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.080830e+18</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>2019-01-03T09:12:07-05:00</td>\n",
       "      <td>RT @senatemajldr Democrats will have to get se...</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>Rep</td>\n",
       "      <td>8-Jan-14</td>\n",
       "      <td>2/16/1955</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1,318,255</td>\n",
       "      <td>729,547</td>\n",
       "      <td>795,696</td>\n",
       "      <td>1,255,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.080890e+18</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>2019-01-03T13:20:53-05:00</td>\n",
       "      <td>Here is a sign of things to come: As Democrats...</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>Rep</td>\n",
       "      <td>8-Jan-14</td>\n",
       "      <td>2/16/1955</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1,318,255</td>\n",
       "      <td>729,547</td>\n",
       "      <td>795,696</td>\n",
       "      <td>1,255,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.080870e+18</td>\n",
       "      <td>RepByrne</td>\n",
       "      <td>2019-01-03T12:10:26-05:00</td>\n",
       "      <td>Let's understand what we're dealing with here:...</td>\n",
       "      <td>Bradley Byrne</td>\n",
       "      <td>Rep</td>\n",
       "      <td>8-Jan-14</td>\n",
       "      <td>2/16/1955</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1,318,255</td>\n",
       "      <td>729,547</td>\n",
       "      <td>795,696</td>\n",
       "      <td>1,255,925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id screen_name                   datetime  \\\n",
       "0  1.081010e+18    RepByrne  2019-01-03T21:23:00-05:00   \n",
       "1  1.080880e+18    RepByrne  2019-01-03T12:30:38-05:00   \n",
       "2  1.080830e+18    RepByrne  2019-01-03T09:12:07-05:00   \n",
       "3  1.080890e+18    RepByrne  2019-01-03T13:20:53-05:00   \n",
       "4  1.080870e+18    RepByrne  2019-01-03T12:10:26-05:00   \n",
       "\n",
       "                                                text name_wikipedia position  \\\n",
       "0  Great news for Baldwin County! The economy of ...  Bradley Byrne      Rep   \n",
       "1  Outstanding news today from @Airbus! @JetBlue ...  Bradley Byrne      Rep   \n",
       "2  RT @senatemajldr Democrats will have to get se...  Bradley Byrne      Rep   \n",
       "3  Here is a sign of things to come: As Democrats...  Bradley Byrne      Rep   \n",
       "4  Let's understand what we're dealing with here:...  Bradley Byrne      Rep   \n",
       "\n",
       "  joined_congress_date   birthday gender state district_number       party  \\\n",
       "0             8-Jan-14  2/16/1955      M    AL               1  Republican   \n",
       "1             8-Jan-14  2/16/1955      M    AL               1  Republican   \n",
       "2             8-Jan-14  2/16/1955      M    AL               1  Republican   \n",
       "3             8-Jan-14  2/16/1955      M    AL               1  Republican   \n",
       "4             8-Jan-14  2/16/1955      M    AL               1  Republican   \n",
       "\n",
       "  trump_2016_state_share clinton_2016_state_share obama_2012_state_share  \\\n",
       "0              1,318,255                  729,547                795,696   \n",
       "1              1,318,255                  729,547                795,696   \n",
       "2              1,318,255                  729,547                795,696   \n",
       "3              1,318,255                  729,547                795,696   \n",
       "4              1,318,255                  729,547                795,696   \n",
       "\n",
       "  romney_2012_state_share  \n",
       "0               1,255,925  \n",
       "1               1,255,925  \n",
       "2               1,255,925  \n",
       "3               1,255,925  \n",
       "4               1,255,925  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_tweets = pd.read_csv(\"data/116th Congressional Tweets and Demographics.csv\")\n",
    "# fill in this line of code with a sufficient number of tweets, depending on your computational resources\n",
    "#congress_tweets = congress_tweets.sample(...)\n",
    "congress_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 1000 rows for writing code\n",
    "congress_tweets = congress_tweets.sample(n = 5000, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36257     Before adopting Olivia, we spent a great amoun...\n",
       "548996    Are we supposed to take Trump seriously or lit...\n",
       "652347    Thank you to Lieutenant Mike Tarr and Fire Chi...\n",
       "267614    Made remarks to @AmFreeSyria sharing my concer...\n",
       "344386    @jeroneanderson @MontcoLP @LelandShow @realDon...\n",
       "                                ...                        \n",
       "808467    RT @Jim_Jordan House Democrats are already dem...\n",
       "708752    RT @SigneWilk Our super spreader president mot...\n",
       "7587      I'm confident Congress will act this week to r...\n",
       "930878    RT @LaurenBlanch12 Studied extra this week for...\n",
       "277874    Since 2000, the measles vaccine has saved over...\n",
       "Name: text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "congress_tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in working with text data is to preprocess it. Make sure you do the following:\n",
    "\n",
    "* Remove punctuation and stop words. The `rem_punc_stop()` function we used in lab is provided to you but you should feel free to edit it as necessary for other steps\n",
    "* Remove tokens that occur frequently in tweets, but may not be helpful for downstream classification. For instance, many tweets contain a flag for retweeting, or share a URL \n",
    "\n",
    "As you search online, you might run into solutions that rely on regular expressions. You are free to use these, but you should also be able to preprocess using the techniques we covered in lab. Specifically, we encourage you to use spaCy's token attributes and string methods to do some of this text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create two dictionaries to add to the default stop words -- one that has a bunch of html gunk, and another that has popular Twitter abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunk = {'\\n',\n",
    " '\\n\\n',\n",
    " '\\n\\n\\n',\n",
    " '\\n\\n\\n\\n',\n",
    " '\\n\\n ',\n",
    " '\\n\\n\\xa0 ',\n",
    " '\\n ',\n",
    " '\\n \\n',\n",
    " '\\n \\n ',\n",
    " '\\n  ',\n",
    " '\\n   ',\n",
    " '\\n\\xa0\\n',\n",
    " ' ',\n",
    " ' \\n',\n",
    " ' \\n\\n',\n",
    " ' \\n ',\n",
    " '  ',\n",
    " '  \\n\\n ',\n",
    " '   ',\n",
    " '     ',\n",
    " '\"',\n",
    " \"'\",\n",
    " '-PRON-','’\t','—','’'} # there's probably a more elegant way to do this than what I did\n",
    "\n",
    "twitter_abbreviations = {'mt','rt','dm','prt','ht','cc'} \n",
    "# lifted from https://www.businessinsider.com/twitter-acronyms-2012-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punc_stop(text):\n",
    "    stop_words = STOP_WORDS\n",
    "    punc = set(punctuation)\n",
    "    \n",
    "    # adds twitter abbreviations to stop words\n",
    "    nlp.Defaults.stop_words |= twitter_abbreviations\n",
    "    \n",
    "    nlp.Defaults.stop_words |= gunk\n",
    "    \n",
    "    # removes punctuation and digits, converts to lowercase\n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc if not ch.isdigit()]).lower()\n",
    "    \n",
    "    # we could remove emojis, but they don't seem to trip up spaCy. Still need to get this to work\n",
    "    # punc_emoji_free = give_emoji_free_text(punc_free)\n",
    "    \n",
    "    doc = nlp(punc_free)\n",
    "    \n",
    "    # lemmatizes rather than just tokenizing\n",
    "    spacy_words = [token.lemma_ for token in doc]\n",
    "    \n",
    "    spacy_words = [word for word in spacy_words if not word.startswith('http')]\n",
    "    \n",
    "    # my more elegant way of removing the new lines lies broken here\n",
    "    #spacy_words = [ x for x in spacy_words if '\\n' in x ]\n",
    "    \n",
    "    no_punc = [word for word in spacy_words if word not in stop_words]\n",
    "    \n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_tweets['tokens'] = [rem_punc_stop(x) for x in congress_tweets['text']]\n",
    "congress_tweets['tokens'] # note -- -PRON- refers to pronoun, the lemmatizer does this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at the tokens\n",
    "#tokens_reduced = []\n",
    "#tokens_reduced = [tokens_reduced.append(word) for word in congress_tweets['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've obtained the lemmas for each tweet, we'll want to count them for text featurization. One way to do this is via the bag-of-words approach. We'll use the function that we built to remove the stop words and punctuation, and lemmatize, to initialize our CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "bow_vector = CountVectorizer(tokenizer = rem_punc_stop, ngram_range=(1,1))\n",
    "bow_matrix = bow_vector.fit_transform(congress_tweets['text'])\n",
    "bow_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = bow_vector.get_feature_names()\n",
    "feature_names[0:50] # peek at our features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, these feature names seem fairly reasonable. However, the tf-idf matrix is an extension of the bag-of-words approach that should be more helpful to us, because it removes very common words that don't add much to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = rem_punc_stop)\n",
    "matrix = tfidf_vector.fit_transform(congress_tweets['text'])\n",
    "matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use two of the techniques we covered in lab (or other techniques outside of lab!) to explore the text of the tweets. You should construct these visualizations with an eye toward the eventual classification tasks: (1) predicting the legislator's political party based on the text of their tweet, and (2) predicting whether the legislator is a Senator or Representative. As a reminder, in lab we covered word frequencies, word clouds, word/character counts, scattertext, and topic modeling as possible exploration tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA 1: A look at the top n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to visualize the most commonly-used words and phrases in our dataset. First, we'll try unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the BOW countervectorizer with ngram_range argument\n",
    "countvec = CountVectorizer(tokenizer = rem_punc_stop, ngram_range=(1,1))\n",
    "ngrams = countvec.fit_transform(congress_tweets['text'])\n",
    "\n",
    "dictionary_dataframe = pd.DataFrame(ngrams.todense(), columns = countvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram = pd.DataFrame(dictionary_dataframe.sum().reset_index()).rename(columns={'index': 'ngrams', 0:'freq'})\n",
    "df_ngram = df_ngram.sort_values(by = ['freq'], ascending = False).reset_index(drop = True)\n",
    "df_ngram.head() # take a peek\n",
    "\n",
    "# interesting. What the heck is 'amp'? Am I just old...?\n",
    "# hmm, could it be ampersand? -P\n",
    "# that's a good guess Paul, I have no idea what amp is. I, too, am old lol -JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, but pretty devoid of context. Let's calculate and visualize the top 25 bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the BOW countervectorizer with ngram_range argument up to 2\n",
    "countvec = CountVectorizer(tokenizer = rem_punc_stop, ngram_range=(2,2))\n",
    "ngrams = countvec.fit_transform(congress_tweets['text'])\n",
    "\n",
    "dictionary_dataframe = pd.DataFrame(ngrams.todense(), columns = countvec.get_feature_names())\n",
    "df_ngram = pd.DataFrame(dictionary_dataframe.sum().reset_index()).rename(columns={'index': 'ngrams', 0:'freq'})\n",
    "df_ngram = df_ngram.sort_values(by = ['freq'], ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"ngrams\", y = 'freq', data=df_ngram[0:25])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigrams seem pretty intelligible indeed. Healthcare was tweeted about the most, with President Trump as a close second. Small business comes in third. It will be interesting to understand the extent to which themes of health versus economy sort themselves along party lines. Likewise, it will be interesting to understand the sentiment of the tweets mentioning Trump, and the extent to which it falls along party lines or legislative chambers. For example, if we hypothesize that the Senate is the \"cooling saucer\" of Congress, perhaps senators' tweets refrain from critiquing Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA 2: A first pass at LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do these tokens combine to compose topics in the 116th Congressional tweets? Let's use LDA to take an initial look. First, we'll create our tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = congress_tweets['text']\n",
    "tf = TfidfVectorizer(tokenizer = rem_punc_stop)\n",
    "\n",
    "tfidf_matrix =  tf.fit_transform(X)\n",
    "dense_matrix = tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit the LDA model, arbitrarily starting with five topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=6, max_iter=20, random_state=0)\n",
    "lda = lda.fit(dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the top tokens for each of our five topics, and print them along with our feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #{}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = tf.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics don't seem super well-separated or coherent, so we may have to play around with the number of components. For example, 4 out of 5 of the topics contain \"covid\" or coronavirus. This might not be totally worrisome, except that they don't appear to be very distinct in other respects -- most mention work and voting, as well as Congress and the president. Topic 3 appears the most distinact, perhaps a bit antagonistic to Trump or impeachment-related -- it is the only one that does not mention the president or health, but \"impeachment\" as well as words like \"crisis,\" \"fight,\" \"act,\" \"people,\" and \"protect.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the topic distributions for separation across our categories of interest: party and Congress vs. Senate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = lda.transform(tfidf_matrix)\n",
    "topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist_df = pd.DataFrame(topic_dist, columns = [\"Topic \" + str(x) for x in range(0, lda.n_components)])\n",
    "df_w_topics = topic_dist_df.join(congress_tweets.reset_index())\n",
    "df_w_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_w_topics.groupby('party')\n",
    "for i in df_w_topics.columns[0:lda.n_components]:\n",
    "    print(grouped[i].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_w_topics.groupby('position')\n",
    "for i in df_w_topics.columns[0:lda.n_components]:\n",
    "    print(grouped[i].mean().sort_values(ascending=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's analyze the sentiments contained within the tweets. You may use TextBlob or another library for these tasks. Do the following:\n",
    "\n",
    "* Choose two legislators, one who you think will be more liberal and one who you think will be more conservative, and analyze their sentiment and/or subjectivity scores per tweet. For instance, you might do two scatterplots that plot each legislator's sentiment against their subjectivity, or two density plots for their sentiments. Do the scores match what you thought?\n",
    "* Plot two more visualizations like the ones you chose in the first part, but do them to compare (1) Democrats v. Republicans and (2) Senators v. Representatives \n",
    "\n",
    "`TextBlob` has already been imported in the top cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert name_wikipedia column to string \n",
    "congress_tweets['name_wikipedia'] = congress_tweets.name_wikipedia.apply(str)\n",
    "congress_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conservative rep - Chip Roy\n",
    "#congress_tweets.loc[congress_tweets['name_wikipedia'] == 'Chip Roy'] -- ok so this doesn't matter I get the same number of tweets (19) with .loc as I do with the code below\n",
    "roy_tweets = congress_tweets[congress_tweets.name_wikipedia == 'Chip Roy']\n",
    "roy_tweets['polarity'] = roy_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "roy_tweets['subjectivity'] = roy_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "roy_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liberal rep - Ted Lieu\n",
    "lieu_tweets = congress_tweets[congress_tweets.name_wikipedia == 'Ted Lieu']\n",
    "lieu_tweets['polarity'] = lieu_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "lieu_tweets['subjectivity'] = lieu_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "lieu_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data frames\n",
    "tweets_combined = [roy_tweets, lieu_tweets]\n",
    "sentiment_1 = pd.concat(tweets_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment polarity for conservative & liberal legislators\n",
    "sns.displot(sentiment_1, x=\"polarity\", hue = \"name_wikipedia\", col = \"name_wikipedia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment subjectivity for conservative & liberal legislators\n",
    "sns.displot(sentiment_1, x=\"subjectivity\", hue = \"name_wikipedia\", col = \"name_wikipedia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity & subjectivity for Dem tweets \n",
    "dem_tweets = congress_tweets[congress_tweets.party == 'Democrat']\n",
    "dem_tweets['polarity'] = dem_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "dem_tweets['subjectivity'] = dem_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "\n",
    "#Polarity & subjectivity for Republican tweets \n",
    "repub_tweets = congress_tweets[congress_tweets.party == 'Republican']\n",
    "repub_tweets['polarity'] = repub_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "repub_tweets['subjectivity'] = repub_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "\n",
    "#Combine data frames\n",
    "party_combined = [dem_tweets, repub_tweets]\n",
    "sentiment_2 = pd.concat(party_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment polarity for Dems vs. Republicans\n",
    "sns.displot(sentiment_2, x=\"polarity\", hue = \"party\", col = \"party\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment subjectivity for Dems vs. Republicans\n",
    "sns.displot(sentiment_2, x=\"subjectivity\", hue = \"party\", col = \"party\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity & subjectivity for Senate tweets\n",
    "sen_tweets = congress_tweets[congress_tweets.position == 'Sen']\n",
    "sen_tweets['polarity'] = sen_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "sen_tweets['subjectivity'] = sen_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "\n",
    "#Polarity & subjectivity for House tweets\n",
    "rep_tweets = congress_tweets[congress_tweets.position == 'Rep']\n",
    "rep_tweets['polarity'] = rep_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "rep_tweets['subjectivity'] = rep_tweets['tokens'].map(lambda text: TextBlob(text).sentiment.subjectivity)\n",
    "\n",
    "#Combine data frames\n",
    "congress_combined = [sen_tweets, rep_tweets]\n",
    "sentiment_3 = pd.concat(congress_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment polarity for Senate vs. House\n",
    "sns.displot(sentiment_3, x=\"polarity\", hue = \"position\", col = \"position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sentiment subjectivity for Senate vs. House\n",
    "sns.displot(sentiment_3, x=\"subjectivity\", hue = \"position\", col = \"position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going to classification, explore different featurization techniques. Create three dataframes or arrays to represent your text features, specifically:\n",
    "\n",
    "* Features engineered from your previous analysis. For example, word counts, sentiment scores, topic model etc.\n",
    "* A term frequency-inverse document frequency matrix. \n",
    "* An embedding-based featurization (like a document averaged word2vec)\n",
    "\n",
    "In the next section, you will experiment with each of these featurization techniques to see which one produces the best classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineered Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered Features\n",
    "word_count = pd.DataFrame([len(str(x).split()) for x in congress_tweets['tokens']], columns = ['word_count'])\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_count = pd.DataFrame([len(x) for x in congress_tweets['text']], columns = ['character_count'])\n",
    "character_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already generated from EDA\n",
    "\n",
    "topic_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review from sentiment analysis goes here\n",
    "sentiment_combined = [sentiment_1, sentiment_2, sentiment_3]\n",
    "sentiment_score = pd.concat(sentiment_combined).reset_index(drop=True)\n",
    "sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into dataframe\n",
    "engineered_features = topic_dist_df.join(character_count).join(word_count).join(sentiment_score)\n",
    "engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words or Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequency Based featurization\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec model from Google; OPTIONAL depending on your computational resources (the file is ~1 GB)\n",
    "# Also note that this file path assumes that the word vectors are underneath 'data'; you may wish to point to the CSS course repo and change the path\n",
    "# or move the vector file to the project repo \n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our tokenized corpus to update the Google News embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain cfpb['tokens'] model so it has the same dimensions as the google vector\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "word2vec_model = gensim.models.Word2Vec(size = 300, window=5, min_count = 1,\n",
    "                                        workers = (multiprocessing.cpu_count()))\n",
    "word2vec_model.build_vocab(congress_tweets['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the intersect code that loads the Google News embeddings\n",
    "\n",
    "# set lockf = 1 to allow updating\n",
    "\n",
    "word2vec_model.intersect_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)\n",
    "\n",
    "# Finish training model\n",
    "word2vec_model.train(congress_tweets['tokens'], total_examples=3, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring word embeddings (with Google News loaded) using t-SNE visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "#words = list(model.wv.vocab)\n",
    "vector_list = [word2vec_model.wv.__getitem__(word) for word in word2vec_model.wv.vocab]\n",
    "\n",
    "# Create a list of the words corresponding to these vectors\n",
    "words_filtered = [word for word in word2vec_model.wv.vocab]\n",
    "\n",
    "# Zip the words together with their vector representations\n",
    "word_vec_zip = zip(words_filtered, vector_list)\n",
    "\n",
    "# Cast to a dict so we can turn it into a dataframe\n",
    "word_vec_dict = dict(word_vec_zip)\n",
    "word_vec_df = pd.DataFrame.from_dict(word_vec_dict, orient='index')\n",
    "word_vec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks lke our word embeddings pulled out 4,079 unique tokens that matched the criteria for Word2Vec (do we know what these criteria are??) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'pca', perplexity = 30)\n",
    "\n",
    "# Use 400 rows to speed up training time\n",
    "tsne_df = tsne.fit_transform(word_vec_df[:400])\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11.7, 8.27))\n",
    "sns.scatterplot(x = tsne_df[:, 0], y = tsne_df[:, 1], alpha = 0.5)\n",
    "\n",
    "# Use adjustText to jitter the labels\n",
    "from adjustText import adjust_text\n",
    "texts = []\n",
    "words_to_plot = list(np.arange(0, 400, 10))\n",
    "\n",
    "# Append words to list\n",
    "for word in words_to_plot:\n",
    "    texts.append(plt.text(tsne_df[word, 0], tsne_df[word, 1], word_vec_df.index[word], fontsize = 10))\n",
    "    \n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.2, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see so much separation, but can see some potentially meaningful proximities? \n",
    "\n",
    "Towards the upper right: bank, credit, firm, investment, trade, product \n",
    "\n",
    "Also in the vicinity: children, wife \n",
    "\n",
    "And then leftish: comment, story, tell "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to try PCA on the vectors... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = word2vec_model.wv.__getitem__(word2vec_model.wv.vocab)\n",
    "# scale the data\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "# make a PCA\n",
    "w2v_pca = PCA(n_components=2) #set n_components to 2 to graph in 2-D\n",
    "\n",
    "# fit the standardized data\n",
    "Y_pca = w2v_pca.fit_transform(X_std)\n",
    "\n",
    "sns.scatterplot(x = Y_pca[:, 0], y = Y_pca[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "rando = random.sample(list(word2vec_model.wv.vocab), 30)\n",
    "\n",
    "X1 = word2vec_model.wv.__getitem__(rando)\n",
    "pca1 = PCA(n_components=2)\n",
    "result = w2v_pca.fit_transform(X1)\n",
    "result_df = pd.DataFrame(result, columns = ['PC1', 'PC2'], index = rando)\n",
    "sns.scatterplot(x = 'PC1', y = 'PC2', data = result_df)\n",
    "\n",
    "from adjustText import adjust_text\n",
    "texts = []\n",
    "\n",
    "# Append words to list\n",
    "for word in result_df.index:\n",
    "    texts.append(plt.text(result_df.loc[word, 'PC1'], result_df.loc[word, 'PC2'], word, fontsize = 8))\n",
    "    \n",
    "# Plot text using adjust_text (because overlapping text is hard to read)\n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.4, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lol well... Interesting that both \"protect\" and \"govt\" are quite far from the mass of the (randomly sampled) vocabulary, and also somewhat far from each other. Also \"october\" and \"twitter\" being close together...? Something about the leadup to the November election? Sorry this is not a particularly well thought out interpretation LOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the averaged embeddings for each document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to average word embeddings for a document; \n",
    "#use examples from lab to apply this function. You can use also other techniques such as PCA and doc2vec instead.\n",
    "\n",
    "#added the else clause in the return statement for any docs that have no words in the model vocab\n",
    "\n",
    "def document_vector(word2vec_model, doc):\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.vocab]\n",
    "    return np.mean(word2vec_model.wv.__getitem__(doc), axis=0) if len(doc) > 0 else np.empty(word2vec_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.vstack takes the list from the list comprehension code\n",
    "# and \"stacks\" vertically to form a single array \n",
    "docavgs = np.vstack([document_vector(word2vec_model, x) for x in congress_tweets['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'pca', perplexity = 30)\n",
    "\n",
    "# Use 400 rows to speed up training time\n",
    "tsne_df = tsne.fit_transform(docavgs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (11.7, 8.27))\n",
    "sns.scatterplot(x = tsne_df[:, 0], y = tsne_df[:, 1], alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lol just one big blob :( \n",
    "\n",
    "Just curious... going to PCA the word averaged document embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = docavgs\n",
    "# scale the data\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "# make a PCA\n",
    "w2v_pca = PCA(n_components=2) #set n_components to 2 to graph in 2-D\n",
    "\n",
    "# fit the standardized data\n",
    "Y_pca = w2v_pca.fit_transform(X_std)\n",
    "\n",
    "sns.scatterplot(x = Y_pca[:, 0], y = Y_pca[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay two clusters !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(data = Y_pca\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of Document Averages\",fontsize=20)\n",
    "targets = set(congress_tweets['party'])\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = congress_tweets.reset_index()['party'] == target\n",
    "    plt.scatter(pca_df.loc[indicesToKeep, 'principal component 1']\n",
    "               , pca_df.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(['Republican', 'Democrat'],prop={'size': 15})\n",
    "\n",
    "from adjustText import adjust_text\n",
    "texts = []\n",
    "\n",
    "# Append name_wikipedia to list\n",
    "# this looks very bad lol, too many names\n",
    "'''for word in pca_df.index:\n",
    "    texts.append(plt.text(pca_df.loc[word, 'principal component 1'],\n",
    "                          pca_df.loc[word, 'principal component 1'], \n",
    "                          congress_tweets.reset_index().loc[word, 'name_wikipedia'], fontsize = 8))\n",
    "    \n",
    "# Plot text using adjust_text (because overlapping text is hard to read)\n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.4, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))'''\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1',fontsize=20)\n",
    "plt.ylabel('Principal Component - 2',fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of Document Averages\",fontsize=20)\n",
    "targets = set(congress_tweets['position'])\n",
    "colors = ['m', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = congress_tweets.reset_index()['position'] == target\n",
    "    plt.scatter(pca_df.loc[indicesToKeep, 'principal component 1']\n",
    "               , pca_df.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um... If there is a separation, doesn't look like it's super meaningful to our questions lol. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# binarize label\n",
    "lb_style = LabelBinarizer()\n",
    "y = congress_tweets['party'] = lb_style.fit_transform(congress_tweets['party'])\n",
    "\n",
    "# train/test split\n",
    "train, test = train_test_split(congress_tweets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_train_tagged = train.apply(lambda r: TaggedDocument(words=r['tokens'], tags=[r.party]), axis=1)\n",
    "ct_test_tagged = test.apply(lambda r: TaggedDocument(words=r['tokens'], tags=[r.party]), axis=1)\n",
    "\n",
    "ct_train_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cpu_count())\n",
    "model_dbow.build_vocab([x for x in tqdm(ct_train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(ct_train_tagged.values)]), \n",
    "                     total_examples=len(ct_train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, ct_train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, ct_test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state=10), \n",
    "                             LogisticRegression())\n",
    "\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'logisticregression__solver' : ['newton-cg', 'lbfgs', 'saga'],\n",
    "             \"logisticregression__max_iter\": [1000], \n",
    "             'logisticregression__l1_ratio': np.arange(0, 1, 0.2)}\n",
    "\n",
    "log_grid_reg3 = GridSearchCV(imba_pipeline, param_grid, cv=3, iid=False, \n",
    "                            scoring=['accuracy', 'precision', 'recall', 'f1'], n_jobs = -1,  \n",
    "                           refit = 'accuracy') \n",
    "log_grid_reg3.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"params\", \"mean_test_accuracy\", \"mean_test_precision\", \n",
    "           \"mean_test_recall\", \"mean_test_f1\", \"mean_fit_time\"]\n",
    "\n",
    "for i in metrics:\n",
    "    print(i, \":\", log_grid_reg3.cv_results_[i][log_grid_reg3.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = log_grid_reg3.best_estimator_[1].predict(StandardScaler().fit_transform(X_test))\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred, normalize = \"true\")\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix, range(2),\n",
    "                  range(2))\n",
    "\n",
    "df_cm = df_cm.rename(index=str, columns={0: \"Republican\", 1: \"Democrat\"})\n",
    "df_cm.index = [\"Republican\", \"Democrat\"]\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, \n",
    "           annot=True,\n",
    "           annot_kws={\"size\": 16},\n",
    "           fmt='g')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec model from Google; OPTIONAL depending on your computational resources (the file is ~1 GB)\n",
    "# Also note that this file path assumes that the word vectors are underneath 'data'; you may wish to point to the CSS course repo and change the path\n",
    "# or move the vector file to the project repo \n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to average word embeddings for a document; use examples from lab to apply this function. You can use also other techniques such as PCA and doc2vec instead.\n",
    "def document_vector(word2vec_model, doc):\n",
    "    doc = [word for word in doc if word in model.wv.vocab]\n",
    "    return np.mean(model.wv.__getitem__(doc), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding based featurization\n",
    "model = gensim.models.Word2Vec(congress_tweets['tokens'], size=100, window=5, \\\n",
    "                               min_count=5, sg=0, alpha=0.025, iter=5, batch_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [word for word in congress_tweets.reset_index()['tokens'][0] if word in model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_vector(model, congress_tweets.reset_index()['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = [document_vector(model, x) for x in congress_tweets.reset_index()['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either use cross-validation or partition your data with training/validation/test sets for this section. Do the following:\n",
    "\n",
    "* Choose a supervised learning algorithm such as logistic regression, random forest etc. \n",
    "* Train six models. For each of the three dataframes you created in the featurization part, train one model to predict whether the author of the tweet is a Democrat or Republican, and a second model to predict whether the author is a Senator or Representative.\n",
    "* Report the accuracy and other relevant metrics for each of these six models.\n",
    "* Choose the featurization technique associated with your best model. Combine those text features with non-text features. Train two more models: (1) A supervised learning algorithm that uses just the non-text features and (2) a supervised learning algorithm that combines text and non-text features. Report accuracy and other relevant metrics. \n",
    "\n",
    "If time permits, you are encouraged to use hyperparameter tuning or AutoML techniques like TPOT, but are not explicitly required to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Six Models with Just Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jasmine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# six models ([engineered features, frequency-based, embedding] * [democrat/republican, senator/representative])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineered Features (trying this without to resolve error below)\n",
    "#dataframes = [engineered_features]\n",
    "\n",
    "#featurization_technique = ['Engineered Text Features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "engineered_features_df = pd.DataFrame(engineered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for dataframe, featurization in zip(dataframes, featurization_technique): (trying to resolve error)\n",
    "lb_style = LabelBinarizer()\n",
    "y = congress_tweets['party_binary'] = lb_style.fit_transform(congress_tweets['party'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(engineered_features_df, \n",
    "                                                    y, \n",
    "                                                    train_size = .80, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state = 10)\n",
    "# create a model\n",
    "logit_reg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logit_model = logit_reg.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred = logit_model.predict(X_test)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred, normalize = \"true\")\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix, range(2),\n",
    "                  range(2))\n",
    "\n",
    "df_cm = df_cm.rename(index=str, columns={0: \"Republican\", 1: \"Democrat\"})\n",
    "df_cm.index = [\"Republican\", \"Democrat\"]\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.set(font_scale=1.4)#for label size\n",
    "sns.heatmap(df_cm, \n",
    "           annot=True,\n",
    "           annot_kws={\"size\": 16},\n",
    "           fmt='g')\n",
    "\n",
    "plt.title('Google Document Averaged Embeddings')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X_std = StandardScaler().fit_transform(np.concatenate((np.array(engineered_features),docavgs), axis = 1))\n",
    "#X_std\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "#y = lb.fit_transform(congress_tweets['party'].replace('Independent', 'Democrat'))\n",
    "\n",
    "y = congress_tweets['party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state=10), \n",
    "                             LogisticRegression())\n",
    "\n",
    "param_grid = {'logisticregression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'logisticregression__solver' : ['newton-cg', 'lbfgs', 'saga'],\n",
    "             \"logisticregression__max_iter\": [1000], \n",
    "             'logisticregression__l1_ratio': np.arange(0, 1, 0.2)}\n",
    "\n",
    "log_grid_reg3 = GridSearchCV(imba_pipeline, param_grid, cv=3, iid=False, \n",
    "                            scoring=['accuracy', 'precision', 'recall', 'f1'], n_jobs = -1,  \n",
    "                           refit = 'accuracy') \n",
    "log_grid_reg3.fit(X_std, y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [\"params\", \"mean_test_accuracy\", \"mean_test_precision\", \n",
    "           \"mean_test_recall\", \"mean_test_f1\", \"mean_fit_time\"]\n",
    "\n",
    "for i in metrics:\n",
    "    print(i, \":\", log_grid_reg3.cv_results_[i][log_grid_reg3.best_index_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn tfidf matrix into data frame\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.todense(), columns = tf.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tfidf df with tweets df to enable dropping independents\n",
    "\n",
    "tweets_plus_tfidf = congress_tweets.reset_index(drop = True).join(tfidf_df, rsuffix = '_right')\n",
    "# using the rsuffix argument because some columns that correspond to tokens duplicate non-text feature titles\n",
    "tweets_plus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop independents\n",
    "\n",
    "tweets_plus_tfidf_no_ind = tweets_plus_tfidf[ tweets_plus_tfidf.party != 'Independent' ]\n",
    "tweets_plus_tfidf_no_ind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tweets_plus_tfidf_no_ind.columns) # look at the column names -- must delete 0-16 again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our features, which consist in tf-idf values for each token in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_plus_tfidf_no_ind.drop(['tweet_id',\n",
    " 'screen_name',\n",
    " 'datetime',\n",
    " 'text',\n",
    " 'name_wikipedia',\n",
    " 'position',\n",
    " 'joined_congress_date',\n",
    " 'birthday',\n",
    " 'gender',\n",
    " 'state',\n",
    " 'district_number',\n",
    " 'party',\n",
    " 'trump_2016_state_share',\n",
    " 'clinton_2016_state_share',\n",
    " 'obama_2012_state_share',\n",
    " 'romney_2012_state_share',\n",
    " 'tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our vector of target values, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb_style = LabelBinarizer()\n",
    "y_party = lb_style.fit_transform(tweets_plus_tfidf_no_ind['party']) # predict party affiliation\n",
    "y_position = lb_style.fit_transform(tweets_plus_tfidf_no_ind['position']) # predict position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our train and test sets, fit a logit model using the training data, and predict y values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [y_party, y_position]\n",
    "\n",
    "target_title = ['Party', 'Senator or Representative?']\n",
    "\n",
    "cm_cols = [{0: \"Republican\", 1: \"Democrat\"}, {0: \"Senator\", 1: \"Representative\"}]\n",
    "\n",
    "cm_cols_index = [[\"Republican\", \"Democrat\"], [\"Senator\", \"Representative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for target_vals in target:\n",
    "    \n",
    "    imba_pipeline = make_pipeline(SMOTE(random_state=10),\n",
    "                             LogisticRegression())\n",
    "    \n",
    "    param_grid = {'logisticregression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "              'logisticregression__solver' : ['newton-cg', 'lbfgs', 'saga'],\n",
    "             \"logisticregression__max_iter\": [1000],\n",
    "             'logisticregression__l1_ratio': numpy.arange(0, 1, 0.2)}\n",
    "    \n",
    "    log_grid_reg3 = GridSearchCV(imba_pipeline, param_grid, cv=3, iid=False,\n",
    "                            scoring=['accuracy', 'precision', 'recall', 'f1'], n_jobs = -1, \n",
    "                           refit = 'accuracy')\n",
    "    \n",
    "    log_grid_reg3.fit(X, target_vals.ravel())\n",
    "    \n",
    "    metrics = [\"params\", \"mean_test_accuracy\", \"mean_test_precision\",\n",
    "           \"mean_test_recall\", \"mean_test_f1\", \"mean_fit_time\"]\n",
    "    \n",
    "    for i in metrics:\n",
    "        print(i, \":\", log_grid_reg3.cv_results_[i][log_grid_reg3.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# re-run the model with the hyperparameters above\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "for target_vals, target_name, cmc, cmci in zip(target, target_title, cm_cols, cm_cols_index):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        target_vals, \n",
    "                                                        train_size = .80, \n",
    "                                                        test_size=0.20, \n",
    "                                                        random_state = 10)\n",
    "    \n",
    "    \n",
    "    # insert hyperparameters here\n",
    "    logit_reg = LogisticRegression(l1_ratio = 0.0,\n",
    "                              #fit_intercept = True,\n",
    "                              penalty = 'l2',\n",
    "                              solver = 'newton-cg')\n",
    "    \n",
    "    # fit the model\n",
    "    logit_model = logit_reg.fit(X_train, y_train.ravel())\n",
    "\n",
    "    y_pred = logit_model.predict(X_test)\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_test, y_pred, normalize = \"true\")\n",
    "\n",
    "    df_cm = pd.DataFrame(cf_matrix, range(2),\n",
    "                      range(2))\n",
    "\n",
    "    df_cm = df_cm.rename(index=str, columns=cmc)\n",
    "    df_cm.index = cmci\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, \n",
    "               annot=True,\n",
    "               annot_kws={\"size\": 16},\n",
    "               fmt='g')\n",
    "\n",
    "    plt.title(target_name)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Combined Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two models ([best text features + non-text features] * [democrat/republican, senator/representative])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do standard preprocessing techniques need to be further customized to a particular corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Did you find evidence for the idea that Democrats and Republicans have different sentiments in their tweets? What about Senators and Representatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Why is validating your exploratory and unsupervised learning approaches with a supervised learning algorithm valuable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Did text only, non-text only, or text and non-text features together perform the best? What is the intuition behind combining text and non-text features in a supervised learning algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer Here**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
